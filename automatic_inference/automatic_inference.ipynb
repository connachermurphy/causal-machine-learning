{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Inference\n",
    "I implement the procedure described in [Farrell, Liang, and Misra (2021)](https://arxiv.org/abs/2010.14694). I make use of R code provided in the Causal Machine Learning course offered in the Fall of 2023 by Max Farrell and Sanjog Misra.\n",
    "\n",
    "Our data consists of $\\boldsymbol{X}$ (`dnn_features`), $Y$ (`outcomes`), and $\\boldsymbol{Z}$ (`structural_features`). We define a set of parameter functions $\\boldsymbol{\\theta}(\\boldsymbol{X})$ (`structural_parameters`). The estimand is the expected value of a statistic $\\boldsymbol{H}$: $\\mu_0 = \\mathbb{E}[\\boldsymbol{H}(\\boldsymbol{X},\\boldsymbol{\\theta}(\\boldsymbol{X}); \\boldsymbol{Z})]$. The outcome variable $Y$ is linked to the parameter functions $\\mathbf{\\theta}(\\cdot)$ by the equality $\\mathbb{E}[Y | \\mathbf{X} = \\mathbf{x}, \\mathbf{Z} = \\mathbf{z}] = G(\\mathbf{\\theta}(\\boldsymbol{X}), \\boldsymbol{Z})$, where we call $G(\\cdot, \\cdot)$ the structural layer (`structural_layer`).\n",
    "\n",
    "When projecting the hessian of the loss function onto $\\boldsymbol{X}$ for the estimation of $\\boldsymbol{\\Lambda}(\\boldsymbol{X})$, it is sometimes possible to avoid estimation. For example, with a linear $G(\\boldsymbol{\\theta}(\\boldsymbol{X}), \\boldsymbol{Z})$ and squared loss, we can compute the hessian directly. This code does _not_ account for such possibilities and will rely on automatic differentiation for the hessian and a DNN for the projection of this hessian onto X\n",
    "\n",
    "### To do:\n",
    "| Task | Status | Notes |\n",
    "|-|-|-|\n",
    "| Accommodate vector statistics | Not started | Check use of `statistic_dim` in `automatic_inference.py` |\n",
    "| Create a general-use function for sample splits | Not started | Need to check handling of remainder cases |\n",
    "| Add diagnostics for structural parameter estimation | Not started | Start with code for CML final |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import automatic_inference as auto_inf\n",
    "\n",
    "import numpy as np\n",
    "# import torch.linalg as linalg\n",
    "# import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data generating process (DGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)  # Set the seed for reproducibility\n",
    "\n",
    "N = 18000  # observation count\n",
    "K = 2  # feature count\n",
    "\n",
    "# Draw independent features from standard normal\n",
    "dnn_features = torch.randn(N, K)\n",
    "\n",
    "# Build the structural parameters from features\n",
    "structural_parameters = torch.cat(\n",
    "    (dnn_features[:, 0].view(N, 1), 3 + dnn_features[:, 1].view(N, 1)), dim=1\n",
    ")\n",
    "structural_parameters_dim = structural_parameters.shape[1]\n",
    "\n",
    "# The structural feature is a binary treatment indicator\n",
    "structural_features = 1 * (torch.randn(N, 1) > 0).view(N, 1)\n",
    "\n",
    "\n",
    "# Define the correspondence between structural parameters and structural features\n",
    "# We use a linear correspondence here; let's not get too crazy\n",
    "# CM: this is a pretty common structural layer, so I should move it to the .py file\n",
    "def structural_layer(structural_parameters, structural_features):\n",
    "    structural_layer_eval = structural_parameters[:, 0:1] + torch.sum(\n",
    "        (structural_features * structural_parameters[:, 1:]), axis=1, keepdim=True\n",
    "    )\n",
    "\n",
    "    return structural_layer_eval\n",
    "\n",
    "\n",
    "# Calculate outcomes (structural component + noise)\n",
    "outcomes_structural = structural_layer(structural_parameters, structural_features)\n",
    "outcomes = outcomes_structural + torch.randn(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM: create a function for sample splits\n",
    "# CM: check N / splits != integer case\n",
    "\n",
    "# Create splits\n",
    "perm = torch.randperm(N)  # create a permutation of the indices\n",
    "\n",
    "num_splits = 3  # number of splits\n",
    "\n",
    "split_size = N // num_splits  # compute the size of each split\n",
    "\n",
    "splits = []  # store splits in a list of dictionaries\n",
    "for s in range(num_splits):\n",
    "    indices = perm[s * split_size : (s + 1) * split_size]\n",
    "\n",
    "    # Use indices to create a split\n",
    "    split = {\n",
    "        \"dnn_features\": dnn_features[indices],\n",
    "        \"structural_features\": structural_features[indices],\n",
    "        \"outcomes\": outcomes[indices],\n",
    "        \"structural_parameters\": structural_parameters[indices],\n",
    "    }\n",
    "\n",
    "    # Add the split to the list of splits\n",
    "    splits.append(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Estimate structural parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_sizes = [30, 30]\n",
    "dropout_rate = 0.0\n",
    "learning_rate = 5e-3\n",
    "weight_decay = 0.0  # no L2 regularization\n",
    "# num_epochs = 2000\n",
    "num_epochs = 2000\n",
    "\n",
    "# Initialize loss function; we use mean squared error\n",
    "loss_function = nn.MSELoss(reduction = \"mean\")\n",
    "\n",
    "# We will initialize the model and optimizer in each loop below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating structural parameters\n",
      "Split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 750.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 750.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 749.61it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimating structural parameters\")\n",
    "\n",
    "models_structural_parameters = []  # trained models for structural parameters\n",
    "\n",
    "for split in range(num_splits):\n",
    "    print(f\"Split {split + 1}\")\n",
    "\n",
    "    # Initialize neural network\n",
    "    model = auto_inf.DeepNeuralNetworkReLU(\n",
    "        input_dim=K,\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        output_dim=structural_parameters_dim,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "\n",
    "    # Initialize optimizer; we use stochastic gradient descent\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model_fit = auto_inf.train_dnn(\n",
    "        splits[split][\"dnn_features\"],\n",
    "        splits[split][\"structural_features\"],\n",
    "        splits[split][\"outcomes\"],\n",
    "        structural_layer,\n",
    "        model,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        num_epochs,\n",
    "    )\n",
    "\n",
    "    models_structural_parameters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM: add diagnostics for structural parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Estimate the conditional expectation of the Hessian of the loss function, $\\boldsymbol{\\Lambda}(\\boldsymbol{X})$\n",
    "That is quite the mouthful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 with structural parameter DNN 3\n",
      "Element (0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 826.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element (0, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 858.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflecting to element (1, 0)\n",
      "Element (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 838.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Split 2 with structural parameter DNN 1\n",
      "Element (0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 856.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element (0, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 867.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflecting to element (1, 0)\n",
      "Element (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 879.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Split 3 with structural parameter DNN 2\n",
      "Element (0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 865.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element (0, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 848.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflecting to element (1, 0)\n",
      "Element (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 863.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_expected_hessian = []  # trained models for expected hessians\n",
    "\n",
    "models_expected_hessian.append(\n",
    "    auto_inf.estimate_expected_hessian(\n",
    "        splits,\n",
    "        0,\n",
    "        models_structural_parameters,\n",
    "        2,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        structural_layer,\n",
    "        hidden_sizes,\n",
    "        dropout_rate,\n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        num_epochs,\n",
    "    )\n",
    ")\n",
    "models_expected_hessian.append(\n",
    "    auto_inf.estimate_expected_hessian(\n",
    "        splits,\n",
    "        1,\n",
    "        models_structural_parameters,\n",
    "        0,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        structural_layer,\n",
    "        hidden_sizes,\n",
    "        dropout_rate,\n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        num_epochs,\n",
    "    )\n",
    ")\n",
    "models_expected_hessian.append(\n",
    "    auto_inf.estimate_expected_hessian(\n",
    "        splits,\n",
    "        2,\n",
    "        models_structural_parameters,\n",
    "        1,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        structural_layer,\n",
    "        hidden_sizes,\n",
    "        dropout_rate,\n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        num_epochs,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Estimate influence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(x, theta, z):\n",
    "    N = theta.size(0)\n",
    "    return theta[:, 1].view(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_influence_function = []\n",
    "\n",
    "estimates_influence_function.append(\n",
    "    auto_inf.estimate_influence_function(\n",
    "        splits,\n",
    "        0,\n",
    "        models_structural_parameters,\n",
    "        1,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        models_expected_hessian,\n",
    "        2,\n",
    "        structural_layer,\n",
    "        statistic,\n",
    "    )\n",
    ")\n",
    "estimates_influence_function.append(\n",
    "    auto_inf.estimate_influence_function(\n",
    "        splits,\n",
    "        1,\n",
    "        models_structural_parameters,\n",
    "        2,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        models_expected_hessian,\n",
    "        0,\n",
    "        structural_layer,\n",
    "        statistic,\n",
    "    )\n",
    ")\n",
    "estimates_influence_function.append(\n",
    "    auto_inf.estimate_influence_function(\n",
    "        splits,\n",
    "        2,\n",
    "        models_structural_parameters,\n",
    "        0,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        models_expected_hessian,\n",
    "        1,\n",
    "        structural_layer,\n",
    "        statistic,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate influence function values across splits and store as np array\n",
    "estimates_influence_function_np = np.concatenate(\n",
    "    [\n",
    "        estimates_influence_function[0].detach().numpy(),\n",
    "        estimates_influence_function[1].detach().numpy(),\n",
    "        estimates_influence_function[2].detach().numpy(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate estimate and standard error from concatenated influence function\n",
    "est = estimates_influence_function_np.mean()\n",
    "se = math.sqrt(estimates_influence_function_np.var() / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.9894\n",
      "S.E.: 0.0168\n",
      "95% CI: [2.9565, 3.0222]\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "print('Mean:', round(est, 4))\n",
    "print('S.E.:', round(se, 4))\n",
    "print('95% CI: [', round(est - 1.96 * se, 4), ', ',\n",
    "      round(est + 1.96 * se, 4), ']', sep = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-machine-learning-2AFA5HUo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
